# Attendance

  - Tim Miller
  - Damian Valles
  - Adam Carlson
  - Brian Pearce
  - Fed Salsbury
  - Greg Cook
  - Natalie Holzwarth
  - Georgia Saylor
  - Bill Kerr
  - Scott Gayzik

# Agenda

  - Graduation Maintenance Day
  - FY15 Annual Purchase
  - Performance Data
  - SLURM
  - State of Cluster
  - Upcoming Tasks

# Maintenance Day

  - **Scheduled: 5/18 - Graduation Day**
      - Reservation starts at 8AM
      - Ends 5/19 at 8AM (not expected)
      - We will send notification when the cluster is available
  - **UCS Firmware update**
      - Not on the UCS nodes
      - Purpose: UCS M4 nodes will require the update
  - **V7000 Storage**
      - Firmware update:
      - Possible disk firmware update
          - If no jobs are running on the cluster

# Performance Data

  - Data was started to be collected in late October 2014 on Job and
    Node numbers

<!-- end list -->

  - **Average ratios of utilized, idle and under repair cluster nodes
    for each month**

<!-- end list -->

  -
    ![<File:Nodes20142015.png>‎](Nodes20142015.png‎
    "File:Nodes20142015.png‎")

<!-- end list -->

  - **Average ratios of running and waiting cluster jobs for each
    month**

<!-- end list -->

  -
    ![<File:Jobs20142015.png>](Jobs20142015.png "File:Jobs20142015.png")

<!-- end list -->

  - Data was started to be collected in early March 2014 on Core and
    Memory numbers

<!-- end list -->

  - **Average ratios of utilized, idle and under repair number of cores
    for each month**
      - March:
          - Max Utilized Avg = 95.46%
          - Utilized Avg = 78.21%
      - April:
          - Max Utilized Avg = 97.05%
          - Requested Avg = 79.38%
          - Utilized Avg = 76.41%

<!-- end list -->

  -
    ![<File:Cores20142015.png>](Cores20142015.png
    "File:Cores20142015.png")

<!-- end list -->

  - **Average ratios of utilized and idle of the total memory in cluster
    for each month**
      - March:
          - Max Utilized Avg = 12.5%
          - Utilized Avg = 8.61%
      - April:
          - Max Utilized Avg = 36.93 %
          - Requested Avg = 26.15%
          - Utilized Avg = 9.53%

<!-- end list -->

  -
    ![<File:Memory20142015.png>](Memory20142015.png
    "File:Memory20142015.png")

# FY15 Annual Purchase

> ## General Approach
>
>   - Primary focus on purchases is core count, not memory
>   - Still maintaining a UCS standard memory configuration of 128GB
>
> :\* All UCS nodes are capable of at least 384GB
>
> ## General Funding Status
>
>   - No external grant funding identified.
>   - Changes at WFBH required us to purchase $11k in storage (16TB raw)
>   - GPFS licensing changes reduced maintenance budget surplus
>   - Would greatly appreciate any supplemental department, startup, or
>     indirect funding
>
> ## Proposed Configuration
>
>   - 2 Chassis, 16 blades total
>   - 512 total cores (Dual Intel E5-2698 v3 processors, 2.30 GHz,
>     16-cores/processor)
>   - 2TB RAM total (128GB/blade on 16 blades)
>   - 300GB/blade (SSD drives *almost* cheap enough)
>   - 20GE/blade network connectivity, 40GE/chassis
>
> :\* Will reduce two original chassis from 40GE/chassis to 20GE/chassis
>
>   - Received an extra 10% in discounting from Cisco in order to meet
>     the budget target and fill out the chassis.

# SLURM

![<File:SLURM_repcom_final.pdf>](SLURM_repcom_final.pdf
"File:SLURM_repcom_final.pdf")

# State of the Cluster

  - **New ARCHIVE Space**
      - EMC VNX 5600
      - On the headnodes: /archive1
      - 16TB - Raw
      - 12TB - Usable
  - **UCS Additional Nodes**
      - Chassis: two nodes in 5; full 6, 7, 8
      - Total 540 cores; 20 per node
  - **OFFLINED Nodes**
      - BC13BL14 - Bad Hard Drive (Out of Warranty)
      - BC14BL11 - Bad Memory DIMM (Out of Warranty)
  - **Decommisioned**
      - DS3400 Storage Array
      - BC08BL05 - Bad Hard Drive (Out of Warranty)
      - BCG01 Nodes
      - BCG03 Nodes
  - **Out of Warranty**
      - BC03 Nodes 4/20/15
      - BC06 Nodes 4/20/15
  - **Upcoming IBM Expirations**
      - RHEL6HEAD1 6/30/15
      - RHEL6HEAD2 6/30/15
      - RHEL6HEAD3 6/30/15
      - BC05 Nodes 8/2/15
      - BC101BL02 9/5/15
      - BC101BL13 9/5/15
      - BC102BL02 9/5/15
      - BC102BL13 9/5/15
      - BC09\[BL09-BL14\] 1/6/16

# Upcoming Tasks

  - RHEL7 upgrade to head and compute nodes
      - GPFS is now supported on RHEL7
      - Testing and collaboration for
          - Compiling software
          - Software installation options
          - Software operation
          - Software versions
      - RHEL4 tools still required??

[Category:WFU DEAC Repcom
Meetings](Category:WFU_DEAC_Repcom_Meetings "wikilink")
